{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bqn4jDHvILPd",
    "outputId": "6253614b-59a1-4da3-8a2f-bc02a58f83f9"
   },
   "outputs": [],
   "source": [
    "files_path = 'insert_path_for_data_set'\n",
    "new_data_files_path = 'insert_path_for_results'\n",
    "running_number = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 945
    },
    "id": "B5-943hvQEAk",
    "outputId": "c0ba00cb-cec3-4180-d38f-4f84d12aa2a5"
   },
   "outputs": [],
   "source": [
    "from ctypes import Structure\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "import cmath\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [7.5, 3.5]\n",
    "\n",
    "second = 1\n",
    "fs = second * 1e-15\n",
    "ps = second * 1e-12\n",
    "meter = 1\n",
    "nm = meter * 1e-9\n",
    "um = meter * 1e-6\n",
    "mm = meter * 1e-3\n",
    "\n",
    "pad = 500  # 500\n",
    "N_samples = 2 ** 10  # 10000\n",
    "c_const = 3e8 * meter / second\n",
    "n_ref = 1\n",
    "\n",
    "dt = (2 * pad * fs) / N_samples\n",
    "t_vec = np.arange(-pad * fs, pad * fs + dt, dt)\n",
    "\n",
    "with open(files_path + \"/data_5layers_20000.npy\", 'rb') as f:\n",
    "    vec_structure = np.load(f)\n",
    "    vec_T = np.load(f)\n",
    "    vec_R = np.load(f)\n",
    "\n",
    "print(vec_structure.shape)\n",
    "print(vec_T.shape)\n",
    "print(vec_R.shape)\n",
    "\n",
    "def non_zero(x_vec, y_vec, min_num=0.001):\n",
    "  i = 0\n",
    "  j = len(x_vec) - 1\n",
    "  while y_vec[i] < min_num:\n",
    "    i = i + 1\n",
    "  while y_vec[j] < min_num:\n",
    "    j = j - 1\n",
    "    # k = min(i , len(x_vec) - j)\n",
    "  return x_vec[i:j], y_vec[i:j]\n",
    "\n",
    "def generate_pulse(index):\n",
    "    plt.figure()\n",
    "    x_in_time, y_in_time = non_zero(t_vec, vec_T[index])\n",
    "    plt.plot(x_in_time, y_in_time)\n",
    "    x_in_time, y_in_time = non_zero(t_vec, vec_R[index])\n",
    "    plt.plot(x_in_time, y_in_time)\n",
    "    plt.legend(['T', 'R'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "def encode_refractive(vec_structure):\n",
    "  for structure in vec_structure:\n",
    "    if structure[0,2] == 'silicon':\n",
    "      structure[0,0] = 0\n",
    "    else:\n",
    "      structure[0,0] = 1\n",
    "  return np.array(vec_structure)\n",
    "\n",
    "\n",
    "generate_pulse(index= random.randint(0,9))\n",
    "vec_structure = vec_structure[:,1:-1,:] #without air\n",
    "vec_structure = encode_refractive(vec_structure)\n",
    "print(vec_structure)\n",
    "vec_structure[:,:,1] = np.float32(vec_structure[:,:,1]) * (10**7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-cXoSBT0lwGH"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def add_pos_2(input,nb):\n",
    "    input_pos_encoding = tf.constant(nb, shape=[input.shape[1]], dtype=\"int32\")/input.shape[1]\n",
    "    input_pos_encoding = tf.cast(tf.reshape(input_pos_encoding, [1,10]),tf.float32)\n",
    "    input = tf.add(input ,input_pos_encoding)\n",
    "    return input\n",
    "\n",
    "def stack_block_transformer(num_transformer_blocks):\n",
    "    input1 = keras.Input(shape=(100, 1))\n",
    "    x = input1\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x,100,2)\n",
    "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
    "    x = layers.Dense(10, activation='selu')(x)\n",
    "    return input1,x\n",
    "\n",
    "def stack_block_transformer_spatial(num_transformer_blocks,x):\n",
    "  for _ in range(num_transformer_blocks):\n",
    "      x = transformer_encoder(x,10*18,2)\n",
    "  x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
    "\n",
    "  return x\n",
    "\n",
    "def transformer_encoder(inputs,key_dim,num_heads):\n",
    "    dropout=0.1\n",
    "    # Normalization and Attention\n",
    "    print(\"transformer_encoder\",inputs.shape)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = layers.MultiHeadAttention(\n",
    "        key_dim=key_dim, num_heads=num_heads\n",
    "    )(x, x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = layers.Dense(key_dim, activation='softmax')(x)\n",
    "    return x + res\n",
    "\n",
    "def add_pos(tensor):\n",
    "  x = np.linspace(0,0.1,1025)\n",
    "  x = tf.constant(x, dtype=tf.float32)\n",
    "  return tf.add(tensor, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KN3GWV_WQSTd",
    "outputId": "b36207f1-8867-48c4-a61c-12b0cae80ad9"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import os\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.layers import Activation\n",
    "import numpy as np\n",
    "np.random.seed(2)\n",
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)\n",
    "#tf.enable_eager_execution()\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras.layers import Dropout, Flatten, Conv1D\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras import backend as K\n",
    "import uuid\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 150\n",
    "random_state = 9990\n",
    "test_size = 0.1\n",
    "\n",
    "x_samples = np.dstack((vec_T, vec_R))\n",
    "y_samples = vec_structure[:,:,:2].astype(np.float32)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_samples, y_samples, \n",
    "                                                    test_size=test_size,\n",
    "                                                    random_state = random_state)\n",
    "\n",
    "x_test, x_dev, y_test, y_dev = train_test_split(x_test, y_test, \n",
    "                                                    test_size=0.5,\n",
    "                                                random_state=0)\n",
    "\n",
    "\n",
    "print('x train')\n",
    "print(x_train.shape)\n",
    "print('x test')\n",
    "print(x_test.shape)\n",
    "print('x dev')\n",
    "print(x_dev.shape)\n",
    "print('y')\n",
    "print(y_train.dtype)\n",
    "\n",
    "# Model\n",
    "num_transformer_blocks_t = 2\n",
    "num_transformer_blocks_r = 1\n",
    "T_vec_input = Input(shape=x_train.shape[1])\n",
    "R_vec_input = Input(shape=x_train.shape[1])\n",
    "#R_vec_first_layer = Dense(512, activation='relu')(R_vec_input)\n",
    "#T_vec_first_layer = Dense(512, activation='relu')(T_vec_input)\n",
    "# R_vec_first_layer = add_pos(R_vec_input)\n",
    "# T_vec_first_layer = add_pos(T_vec_input)\n",
    "\n",
    "# R_vec_first_layer = Dense(512, activation='relu')(R_vec_first_layer)\n",
    "# T_vec_first_layer = Dense(512, activation='relu')(T_vec_first_layer)\n",
    "\n",
    "R_vec_first_layer = R_vec_input\n",
    "T_vec_first_layer = T_vec_input\n",
    "\n",
    "t = tf.expand_dims(T_vec_first_layer, -1) #-1 denotes the last dimension\n",
    "t = stack_block_transformer_spatial(num_transformer_blocks_t,t)\n",
    "t = Dropout(0.1)(t)\n",
    "t = layers.Dense(100, activation='selu')(t)\n",
    "r = tf.expand_dims(R_vec_first_layer, -1) #-1 denotes the last dimension\n",
    "r = stack_block_transformer_spatial(num_transformer_blocks_r,r)\n",
    "r = Dropout(0.1)(r)\n",
    "r = layers.Dense(100, activation='selu')(r)\n",
    "\n",
    "concat_first = tf.keras.layers.Concatenate()([r,\n",
    "                                              t])\n",
    "num_transformer_blocks = 2\n",
    "x = Dense(512, activation='relu')(concat_first)\n",
    "x = Dense(256, activation='selu')(x)\n",
    "x = tf.expand_dims(x, -1) #-1 denotes the last dimension\n",
    "x = stack_block_transformer_spatial(num_transformer_blocks,x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = layers.Dense(100, activation='selu')(x)\n",
    "x = Dense(25, activation='selu')(x)\n",
    "Width_output = Dense(y_train.shape[1], activation='relu')(x)\n",
    "Refidx_output = Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=[T_vec_input, R_vec_input],\n",
    "              outputs=[Width_output, Refidx_output])\n",
    "\n",
    "model.summary()\n",
    "plot_model(model, \n",
    "           to_file=files_path+'/model_plot.png',\n",
    "           show_shapes=True, show_layer_names=False)\n",
    "\n",
    "\n",
    "# model compilation\n",
    "model.compile(loss=['mae', 'sparse_categorical_crossentropy'], \n",
    "              loss_weights=[1.0, 1.0],\n",
    "              optimizer=tf.keras.optimizers.RMSprop(1e-3),\n",
    "              metrics=['mae'])\n",
    "\n",
    "# save model\n",
    "model_file = files_path+'/model.h5'\n",
    "checkpoint = ModelCheckpoint(model_file, verbose=1, monitor='val_loss', \n",
    "                             save_best_only=True, mode='auto')\n",
    "\n",
    "# model fit\n",
    "history = model.fit([x_train[:,:,0], x_train[:,:,1]], [y_train[:,:,1], y_train[:,0,0]],\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=([x_dev[:,:,0], \n",
    "                            x_dev[:,:,1]], [y_dev[:,:,1], y_dev[:,0,0]]),\n",
    "          callbacks=[checkpoint])\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model mae')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CDUsgy9sL0Hr"
   },
   "outputs": [],
   "source": [
    "loss_history = np.array(history.history['loss'])\n",
    "val_loss_history = np.array(history.history['val_loss'])\n",
    "\n",
    "outfile = new_data_files_path + '/layers5_Transformer_' + str(running_number) + '_history'\n",
    "np.savez(outfile, loss_history = loss_history, val_loss_history = val_loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "GIktQFCBL4yG",
    "outputId": "1ada41fb-e8d0-46fb-9777-9f6db6d6518c"
   },
   "outputs": [],
   "source": [
    "outfile = new_data_files_path + '/layers5_Transformer_' + str(running_number) + '_history.npz'\n",
    "npzfile = np.load(outfile)\n",
    "d = dict(npzfile)\n",
    "plt.figure()\n",
    "plt.plot(d['loss_history'])\n",
    "plt.plot(d['val_loss_history'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "AfGc03mpQSN9",
    "outputId": "9439ecd7-3b01-4acf-c1b7-9a4f863f7c2b"
   },
   "outputs": [],
   "source": [
    "# Graphics that compare structures and waveforms\n",
    "\n",
    "# START- the relevat parts form the pycharm project- The Matrix Method\n",
    "\n",
    "c_const = 3e8 * meter / second\n",
    "n_ref = 1\n",
    "\n",
    "f_vec = np.fft.fftshift(np.fft.fftfreq(t_vec.shape[0], d=dt))\n",
    "omega_vec = (2 * np.pi * f_vec)\n",
    "lambda_vec = (2 * np.pi * c_const / omega_vec)\n",
    "\n",
    "def P_matrix(n, d, wave_length):\n",
    "    phase = 2 * (math.pi / wave_length) * d * n\n",
    "    P11 = cmath.exp(-1j * phase)\n",
    "    P22 = cmath.exp(1j * phase)\n",
    "    P = np.array([[P11, 0], [0, P22]])\n",
    "    return P\n",
    "\n",
    "def T_matrix(n1, n2):\n",
    "    n1 = n1.real\n",
    "    n2 = n2.real\n",
    "    T11 = (n1 + n2) / (2 * n1)\n",
    "    T12 = (n1 - n2) / (2 * n1)\n",
    "    T21 = (n1 - n2) / (2 * n1)\n",
    "    T22 = (n1 + n2) / (2 * n1)\n",
    "    T = np.array([[T11, T12], [T21, T22]])\n",
    "    return T\n",
    "\n",
    "def P_list(NDlist, wave_length):\n",
    "    lis = []\n",
    "    for i in range(len(NDlist) - 2):\n",
    "        n = NDlist[i + 1][0]\n",
    "        d = NDlist[i + 1][1]\n",
    "        lis.append(P_matrix(n, d, wave_length))\n",
    "    return lis\n",
    "\n",
    "def T_list(NDlist):\n",
    "    lis = []\n",
    "    for i in range(len(NDlist) - 1):\n",
    "        lis.append(T_matrix(NDlist[i][0], NDlist[i + 1][0]))\n",
    "    return lis\n",
    "\n",
    "def M_matrix(NDlist, wave_length):\n",
    "    Tlist = T_list(NDlist)\n",
    "    Plist = P_list(NDlist, wave_length)\n",
    "    M = np.array([[1, 0], [0, 1]])\n",
    "    for i in range(len(Plist)):\n",
    "        m = np.dot(Tlist[i], Plist[i])\n",
    "        M = np.dot(M, m)\n",
    "    M = np.dot(M, Tlist[-1])\n",
    "    return M\n",
    "\n",
    "def reflectance(NDlist, wave_length):\n",
    "    M = M_matrix(NDlist, wave_length)\n",
    "    r = M[1][0] / M[0][0]\n",
    "    return r\n",
    "\n",
    "def transmittance(NDlist, wave_length):\n",
    "    M = M_matrix(NDlist, wave_length)\n",
    "    t = 1 / M[0][0]\n",
    "    return t\n",
    "\n",
    "def t_spectrum_vec(NDlist, vec):\n",
    "    lis = []\n",
    "    for i in range(vec.shape[0]):\n",
    "        t = transmittance(NDlist, vec[i])\n",
    "        lis.append(t)\n",
    "    return lis\n",
    "\n",
    "\n",
    "def r_spectrum_vec(NDlist, vec):\n",
    "    lis = []\n",
    "    for i in range(vec.shape[0]):\n",
    "        r = reflectance(NDlist, vec[i])\n",
    "        lis.append(r)\n",
    "    return lis\n",
    "\n",
    "def generate_vector(NDlist):\n",
    "    width_time = 12 * fs\n",
    "    carrier_wavelength = 800 * nm\n",
    "    omega_0 = np.divide((2 * np.pi * c_const), (n_ref * carrier_wavelength))\n",
    "    input_wave_amp = np.exp(- 2 * np.log(2) * np.square(t_vec / (width_time)))\n",
    "    input_wave_phase = 0\n",
    "    input_wave_phase = input_wave_phase + omega_0 * t_vec\n",
    "    input_wave = input_wave_amp * np.exp(1j * input_wave_phase)\n",
    "    input_wave_spectrum = np.fft.fftshift(np.fft.fft(np.fft.ifftshift(input_wave)))\n",
    "    reflected_lambda = r_spectrum_vec(NDlist, lambda_vec) * input_wave_spectrum\n",
    "    transmitted_lambda = t_spectrum_vec(NDlist, lambda_vec) * input_wave_spectrum\n",
    "    output_wave_reflected = np.fft.ifftshift(np.fft.ifft(np.fft.fftshift(reflected_lambda)))\n",
    "    output_wave_transmitted = np.fft.ifftshift(np.fft.ifft(np.fft.fftshift(transmitted_lambda)))\n",
    "    return (np.abs(output_wave_transmitted) ** 2), (np.abs(output_wave_reflected) ** 2)\n",
    "\n",
    "# END- the relevat parts form the pycharm project\n",
    "\n",
    "def create_NDlist(n , d):\n",
    "  NDlist = np.zeros((len(d),2))\n",
    "  for i in range(len(d)):\n",
    "    if i % 2 == n:\n",
    "      NDlist[i,0] = 3.4777237564709433\n",
    "    else:\n",
    "      NDlist[i,0] = 1.4440236216729967\n",
    "  NDlist[:,1] = d\n",
    "  return NDlist\n",
    "\n",
    "def plot_structure(NDlist):\n",
    "  # d1 = int(NDlist[0][1] * (10**7))\n",
    "  # d2 = int(NDlist[1][1] * (10**7))\n",
    "  d = NDlist[:,1] * (10**7)\n",
    "\n",
    "  d_sum = int(np.sum(d))\n",
    "  image = np.zeros((int(d_sum/3) , d_sum))\n",
    "  n = int(NDlist[0][0] < NDlist[1][0])\n",
    "  point = 0\n",
    "  for i in range(len(d)-1):\n",
    "    image[:,point:point+ int(d[i])] = 255 * ((i-n)%2)\n",
    "    point = point + int(d[i])\n",
    "  image[: ,point:] = 255 * ((i-n+1)%2)\n",
    "  return image\n",
    "\n",
    "def add_air(NDlist):\n",
    "  new = np.zeros((NDlist.shape[0] + 2,2))\n",
    "  new[0,0] = 1\n",
    "  new[NDlist.shape[0] + 1,0] = 1\n",
    "  new[0,1] = 0\n",
    "  new[NDlist.shape[0] + 1,1] = 0\n",
    "  new[1:-1, :] = NDlist\n",
    "  return new\n",
    "\n",
    "def calculate_correlation_structure(NDlist_original, NDlist_prediction):\n",
    "  if (NDlist_original[0,0] > 3 and NDlist_prediction[0,0] < 3) or (NDlist_original[0,0] < 3 and NDlist_prediction[0,0] > 3):\n",
    "    return 0\n",
    "  num_of_layers = NDlist_original.shape[0]\n",
    "  corr = 0 \n",
    "  for i in range(num_of_layers):\n",
    "      corr += min(d_original[i], d_prediction[i])/max(d_original[i], d_prediction[i])\n",
    "  corr /= num_of_layers\n",
    "  corr *= 100\n",
    "  corr = int(corr)/100\n",
    "  return corr\n",
    "\n",
    "def correl(x,y):\n",
    "  up = abs(x-y)\n",
    "  down = x+y\n",
    "  correl = 1 - np.average(up/down)\n",
    "  return correl\n",
    "\n",
    "\n",
    "########################################\n",
    "# THE MAIN PART OF THE CODE STARTS HERE!\n",
    "########################################\n",
    "\n",
    "# n_prediction = 0 or 1\n",
    "# d_prediction = [d1 , d2, d3, ... , d20]\n",
    "\n",
    "mm = 10**(-6)\n",
    "\n",
    "for i in range(3):\n",
    "  index = random.randint(0,100)\n",
    "  n_original = y_test[index][0,0]\n",
    "  d_original = y_test[index,:,1] * (10**-7)\n",
    "\n",
    "  y_pred = model.predict([x_test[:,:,0], x_test[:,:,1]])\n",
    "  n_prediction_vector = np.float32(y_pred[1] < 0.5)[:,0]\n",
    "  d_prediction_vector = y_pred[0]* (10**-7)\n",
    "\n",
    "  n_prediction = n_prediction_vector[index]\n",
    "  d_prediction = d_prediction_vector[index]\n",
    "  print(\"\\ni = {}, index = {}\".format(i, index))\n",
    "  print(\"n original:\")\n",
    "  print(n_original)\n",
    "  print(\"d original:\")\n",
    "  print(d_original)\n",
    "  print(\"n prediction:\")\n",
    "  print(n_prediction)\n",
    "  print(\"d prediction:\")\n",
    "  print(d_prediction)\n",
    "\n",
    "  NDlist_original = create_NDlist(n_original, d_original)\n",
    "  NDlist_prediction = create_NDlist(n_prediction, d_prediction)\n",
    "\n",
    "  plt.figure(i)\n",
    "  image_original = plot_structure(NDlist_original)\n",
    "  image_prediction = plot_structure(NDlist_prediction)\n",
    "  plt.subplot(2,2,1)\n",
    "  plt.imshow(image_original)\n",
    "  plt.title('original- one pixel = 100nm')\n",
    "  plt.subplot(2,2,3)\n",
    "  plt.imshow(image_prediction)\n",
    "  plt.title('prediction- one pixel = 100nm')\n",
    "  plt.subplot(2,2,2)\n",
    "  x_t_original, y_t_original = non_zero(t_vec, x_test[index, :,0])\n",
    "  x_r_original, y_r_original = non_zero(t_vec, x_test[index, :,1])\n",
    "  plt.plot(x_t_original, y_t_original)\n",
    "  plt.plot(x_r_original, y_r_original)\n",
    "  plt.legend(['T' , 'R'])\n",
    "  plt.subplot(2,2,4)\n",
    "  y_t_prediction0, y_r_prediction0 = generate_vector(add_air(NDlist_prediction))\n",
    "  x_t_prediction, y_t_prediction = non_zero(t_vec, y_t_prediction0)\n",
    "  x_r_prediction, y_r_prediction = non_zero(t_vec, y_r_prediction0)\n",
    "  plt.plot(x_t_prediction, y_t_prediction)\n",
    "  plt.plot(x_r_prediction, y_r_prediction)\n",
    "  plt.legend(['T' , 'R'])\n",
    "  plt.figure()\n",
    "  plt.subplot(2,1,1)\n",
    "  plt.plot(x_t_original, y_t_original)\n",
    "  plt.plot(x_t_prediction, y_t_prediction)\n",
    "  plt.legend(['orig' , 'pred'])\n",
    "  plt.title('T')\n",
    "  plt.subplot(2,1,2)\n",
    "  plt.plot(x_r_original, y_r_original)\n",
    "  plt.plot(x_r_prediction, y_r_prediction)\n",
    "  plt.legend(['orig' , 'pred'])\n",
    "  plt.title('R')\n",
    "\n",
    "  plt.show()\n",
    "\n",
    "  correlation_t = int(100 * np.abs(np.corrcoef(x_test[index, :,0], y_t_prediction0)[0,1]))\n",
    "  correlation_r = int(100 * np.abs(np.corrcoef(x_test[index, :,1], y_r_prediction0)[0,1]))\n",
    "  correlation_structure = int(calculate_correlation_structure(NDlist_original, NDlist_prediction) * 100)\n",
    "  print(\"correlation t = {}% \\ncorrelation r = {}% \\ncorrelation structure = {}%\".format(correlation_t, correlation_r, correlation_structure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 585
    },
    "id": "gcv0ONn5r2F0",
    "outputId": "4d8b1a2b-0860-4a40-f828-ac02b3922fc6"
   },
   "outputs": [],
   "source": [
    "# Histogram of Correlation for the test set\n",
    "\n",
    "y_pred = model.predict([x_test[:,:,0], x_test[:,:,1]])\n",
    "n_prediction_vector = np.float32(y_pred[1] < 0.5)[:,0]\n",
    "d_prediction_vector = y_pred[0] * (10**-7)\n",
    "\n",
    "def prediction(index, n_prediction_vector, d_prediction_vector):\n",
    "  n_prediction = n_prediction_vector[index]\n",
    "  d_prediction = d_prediction_vector[index]\n",
    "  return n_prediction, d_prediction\n",
    "\n",
    "def ND_to_TR(n_prediction, d_prediction):\n",
    "  NDlist_prediction = create_NDlist(n_prediction, d_prediction)\n",
    "  t_prediction, r_prediction = generate_vector(add_air(NDlist_prediction))\n",
    "  return t_prediction, r_prediction\n",
    "\n",
    "correlation_structure = []\n",
    "vec_t_original = x_test[:,:,0]\n",
    "vec_r_original = x_test[:,:,1]\n",
    "vec_t_prediction = []\n",
    "vec_r_prediction = []\n",
    "refractive_correlation = []\n",
    "for i in range(len(x_test)):\n",
    "  n_prediction, d_prediction = prediction(i, n_prediction_vector, d_prediction_vector)\n",
    "  t_prediction, r_prediction = ND_to_TR(n_prediction, d_prediction)\n",
    "  vec_t_prediction.append(t_prediction)\n",
    "  vec_r_prediction.append(r_prediction)\n",
    "  n_original = y_test[i,0,0]\n",
    "  d_original = y_test[i,:,1]\n",
    "  d_original = d_original * (10**-7)\n",
    "  if n_original == n_prediction:\n",
    "    refractive_correlation.append(1)\n",
    "  else:\n",
    "    refractive_correlation.append(0)\n",
    "  NDlist_original = create_NDlist(n_original, d_original)\n",
    "  NDlist_prediction = create_NDlist(n_prediction, d_prediction)\n",
    "  correlation_structure.append(calculate_correlation_structure(NDlist_original, NDlist_prediction))\n",
    "\n",
    "vec_t_prediction = np.array(vec_t_prediction)\n",
    "vec_r_prediction = np.array(vec_r_prediction)\n",
    "\n",
    "# Calculate correlation\n",
    "correlation_vec_t = []\n",
    "correlation_vec_r = []\n",
    "for i in range(len(x_test)):\n",
    "  correlation_vec_t.append(np.abs(np.corrcoef(vec_t_original[i], vec_t_prediction[i])[0,1]))\n",
    "  correlation_vec_r.append(np.abs(np.corrcoef(vec_r_original[i], vec_r_prediction[i])[0,1]))\n",
    "\n",
    "correlation_structure = np.array(correlation_structure)\n",
    "correlation_vec_t = np.array(correlation_vec_t)\n",
    "correlation_vec_r = np.array(correlation_vec_r)\n",
    "  \n",
    "plt.figure()\n",
    "plt.subplot(1,4,1)\n",
    "plt.title('T')\n",
    "plt.hist(correlation_vec_t)\n",
    "plt.subplot(1,4,2)\n",
    "plt.title('R')\n",
    "plt.hist(correlation_vec_r)\n",
    "plt.subplot(1,4,3)\n",
    "plt.title('Structure')\n",
    "plt.hist(correlation_structure)\n",
    "plt.subplot(1,4,4)\n",
    "plt.title('Refractive')\n",
    "plt.hist(refractive_correlation)\n",
    "plt.show()\n",
    "\n",
    "print('average T: ' + str(int(np.average(correlation_vec_t) * 10000)/100))\n",
    "print('average R: ' + str(int(np.average(correlation_vec_r) * 10000)/100))\n",
    "print('average Structure: ' + str(int(np.average(correlation_structure) * 10000)/100))\n",
    "print('average Refractive: ' + str(int(np.average(refractive_correlation) * 10000)/100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = new_data_files_path + '/layers5_Transformer_' + str(running_number) + '_NDlist'\n",
    "np.savez(outfile, n = n_prediction_vector, d = d_prediction_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = new_data_files_path + '/layers5_Transformer_' + str(running_number) + '_NDlist.npz'\n",
    "npzfile = np.load(outfile)\n",
    "d = dict(npzfile)\n",
    "print(d.keys())\n",
    "print(d['n'].shape)\n",
    "print(d['d'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mSPWIwe-Myib"
   },
   "outputs": [],
   "source": [
    "outfile = new_data_files_path + '/layers5_Transformer_' + str(running_number) + '_examples'\n",
    "savez_dict = {}\n",
    "for i in range(1000):\n",
    "  savez_dict['unknown_layers_Transformer_t_original_example' + str(i)] = vec_t_original[i]\n",
    "  savez_dict['unknown_layers_Transformer_t_prediction_example' + str(i)] = vec_t_prediction[i]\n",
    "  savez_dict['unknown_layers_Transformer_r_original_example' + str(i)] = vec_r_original[i]\n",
    "  savez_dict['unknown_layers_Transformer_r_prediction_example' + str(i)] = vec_r_prediction[i]\n",
    "np.savez(outfile, t_vec = t_vec, **savez_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "H0SI_VJaNTtv",
    "outputId": "7bec5a25-7d09-4ab7-f5e1-b10b00dc1a67"
   },
   "outputs": [],
   "source": [
    "outfile = new_data_files_path + '/layers5_Transformer_' + str(running_number) + '_examples.npz'\n",
    "npzfile = np.load(outfile)\n",
    "d = dict(npzfile)\n",
    "plt.figure()\n",
    "plt.plot(d['unknown_layers_Transformer_r_original_example20'])\n",
    "plt.plot(d['unknown_layers_Transformer_r_prediction_example20'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DFRHQG0HNWhu"
   },
   "outputs": [],
   "source": [
    "outfile = new_data_files_path + '/layers5_Transformer_' + str(running_number) + '_histogram'\n",
    "np.savez(outfile, T_histogram = correlation_vec_t,\n",
    "         R_histogram = correlation_vec_r,\n",
    "         Structure_histogram = correlation_structure,\n",
    "         Refractive_histogram = refractive_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254
    },
    "id": "KMmyDp-DNc36",
    "outputId": "45274640-25a7-4ce9-a218-e20636c52b01"
   },
   "outputs": [],
   "source": [
    "outfile = new_data_files_path + '/layers5_Transformer_' + str(running_number) + '_histogram.npz'\n",
    "npzfile = np.load(outfile)\n",
    "d = dict(npzfile)\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(1,4,1)\n",
    "plt.title('T')\n",
    "plt.hist(d['T_histogram'])\n",
    "plt.subplot(1,4,2)\n",
    "plt.title('R')\n",
    "plt.hist(d['R_histogram'])\n",
    "plt.subplot(1,4,3)\n",
    "plt.title('Structure')\n",
    "plt.hist(d['Structure_histogram'])\n",
    "plt.subplot(1,4,4)\n",
    "plt.title('Refractive')\n",
    "plt.hist(d['Refractive_histogram'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A7lbHwzEPnMl"
   },
   "outputs": [],
   "source": [
    "def subtraction(image_original, image_prediction):\n",
    "  d = max(image_original.shape[1], image_prediction.shape[1])\n",
    "  h = min(image_original.shape[0], image_prediction.shape[0])\n",
    "  sub1 = np.zeros((h,d))\n",
    "  sub1[:,:image_original.shape[1]] = image_original[:h,:]\n",
    "  sub2 = np.zeros((h,d))\n",
    "  sub2[:,:image_prediction.shape[1]] = image_prediction[:h,:]\n",
    "  sub = np.abs(sub1-sub2)\n",
    "  sub = (sub > 1) * 255\n",
    "  sub[:,min(image_original.shape[1], image_prediction.shape[1]):] = 255\n",
    "  return sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p_mthRXoPszj"
   },
   "outputs": [],
   "source": [
    "#generate filter images\n",
    "outfile = new_data_files_path + '/layers5_Transformer_' + str(running_number) + '_filters'\n",
    "savez_dict = {}\n",
    "\n",
    "n_original_vector = y_test[:,0,0]\n",
    "d_original_vector = y_test[:,:,1] * (10**-7)\n",
    "for i in range(1000):\n",
    "  NDlist_original = create_NDlist(n_original_vector[i], d_original_vector[i])\n",
    "  NDlist_prediction = create_NDlist(n_prediction_vector[i], d_prediction_vector[i])\n",
    "  image_original = plot_structure(NDlist_original)\n",
    "  image_prediction = plot_structure(NDlist_prediction)\n",
    "  sub = subtraction(image_original, image_prediction)\n",
    "  savez_dict['original' + str(i)] = image_original\n",
    "  savez_dict['prediction' + str(i)] = image_prediction\n",
    "  savez_dict['subtraction' + str(i)] = sub\n",
    "\n",
    "np.savez(outfile, **savez_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 601
    },
    "id": "9wdjykicP426",
    "outputId": "3bb03a06-02fa-4575-a9af-238d7b184ee9"
   },
   "outputs": [],
   "source": [
    "outfile = new_data_files_path + '/layers5_Transformer_' + str(running_number) + '_filters.npz'\n",
    "npzfile = np.load(outfile)\n",
    "d = dict(npzfile)\n",
    "plt.figure()\n",
    "plt.subplot(3,1,1)\n",
    "plt.imshow(d['original400'])\n",
    "plt.subplot(3,1,2)\n",
    "plt.imshow(d['prediction400'])\n",
    "plt.subplot(3,1,3)\n",
    "plt.imshow(d['subtraction400'])\n",
    "plt.show()\n",
    "print(d['original100'].shape)\n",
    "print(d['prediction100'].shape)\n",
    "print(d['subtraction100'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "jZC1vi_uMQrJ",
    "outputId": "6a6ad441-9d17-48be-afa7-d428d910e65f"
   },
   "outputs": [],
   "source": [
    "# Saving images as PDF\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [15, 7.50]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "for i in range(300):\n",
    "  index = i\n",
    "  n_original = y_test[index][0,0]\n",
    "  d_original = y_test[index,:,1] * (10**-7)\n",
    "\n",
    "  y_pred = model.predict([x_test[:,:,0], x_test[:,:,1]])\n",
    "  n_prediction_vector = np.float32(y_pred[1] < 0.5)[:,0]\n",
    "  d_prediction_vector = y_pred[0]* (10**-7)\n",
    "\n",
    "  n_prediction = n_prediction_vector[index]\n",
    "  d_prediction = d_prediction_vector[index]\n",
    "\n",
    "  NDlist_original = create_NDlist(n_original, d_original)\n",
    "  NDlist_prediction = create_NDlist(n_prediction, d_prediction)\n",
    "\n",
    "  plt.figure()\n",
    "  image_original = plot_structure(NDlist_original)\n",
    "  image_prediction = plot_structure(NDlist_prediction)\n",
    "  correlation_structure = int(calculate_correlation_structure(NDlist_original, NDlist_prediction) * 100)\n",
    "  plt.subplot(3,2,1)\n",
    "  plt.imshow(image_original)\n",
    "  plt.title('original- one pixel = 100nm | structure correlation: {}%'.format(correlation_structure))\n",
    "  plt.subplot(3,2,3)\n",
    "  plt.imshow(image_prediction)\n",
    "  plt.title('prediction- one pixel = 100nm | structure correlation: {}%'.format(correlation_structure))\n",
    "  plt.subplot(3,2,2)\n",
    "  x_t_original, y_t_original = non_zero(t_vec, x_test[index, :,0])\n",
    "  x_r_original, y_r_original = non_zero(t_vec, x_test[index, :,1])\n",
    "  plt.plot(x_t_original, y_t_original)\n",
    "  plt.plot(x_r_original, y_r_original)\n",
    "  plt.legend(['T' , 'R'])\n",
    "  plt.title(\"original\")\n",
    "  plt.subplot(3,2,4)\n",
    "  y_t_prediction0, y_r_prediction0 = generate_vector(add_air(NDlist_prediction))\n",
    "  x_t_prediction, y_t_prediction = non_zero(t_vec, y_t_prediction0)\n",
    "  x_r_prediction, y_r_prediction = non_zero(t_vec, y_r_prediction0)\n",
    "  plt.plot(x_t_prediction, y_t_prediction)\n",
    "  plt.plot(x_r_prediction, y_r_prediction)\n",
    "  plt.legend(['T' , 'R'])\n",
    "  plt.title(\"prediction\")\n",
    "  plt.subplot(3,2,5)\n",
    "  plt.plot(x_t_original, y_t_original)\n",
    "  plt.plot(x_t_prediction, y_t_prediction)\n",
    "  plt.legend(['orig' , 'pred'])\n",
    "  correlation_t = int(100 * np.abs(np.corrcoef(x_test[index, :,0], y_t_prediction0)[0,1]))\n",
    "  plt.title('T - correlation: {}%'.format(correlation_t))\n",
    "  plt.subplot(3,2,6)\n",
    "  plt.plot(x_r_original, y_r_original)\n",
    "  plt.plot(x_r_prediction, y_r_prediction)\n",
    "  plt.legend(['orig' , 'pred'])\n",
    "  correlation_r = int(100 * np.abs(np.corrcoef(x_test[index, :,1], y_r_prediction0)[0,1]))\n",
    "  plt.title('R - correlation: {}%'.format(correlation_r))\n",
    "\n",
    "\n",
    "def save_multi_image(filename):\n",
    "   pp = PdfPages(filename)\n",
    "   fig_nums = plt.get_fignums()\n",
    "   figs = [plt.figure(n) for n in fig_nums]\n",
    "   for fig in figs:\n",
    "      fig.savefig(pp, format='pdf')\n",
    "   pp.close()\n",
    "\n",
    "filename = new_data_files_path + '/layers5_Transformer_' + str(running_number) + '.pdf'\n",
    "save_multi_image(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
